---
title: "Likelihood (MLE and MAP)"
tags:
  - MachineLearning
use_math: true
---

### 머신러닝의 목표 

우리가 가지고 있는 데이터의 분포를 알고 있으면 새로운 입력값이 들어와도 적절한 출력값을 추정할 수 있기 때문에 우리는 데이터가 따르는 확률 분포를 알고 싶어한다. 하지만, 데이터가 따르는 정확한 확률 분포를 구하는 것은 불가능하다. 따라서 parameter에 의해 결정되는 머신러닝 모델을 만들고 parameter값을 조절하는 방식으로 데이터 분포를 표현한다. 

__최적의 parameter 값을 찾아__ 모델이 표현하는 확률 분포를 우리가 가지고 있는 데이터의 실제 분포에 가깝게 만드는 것이 머신러닝의 목표이다. 

> 베이지안 모델은 모델 parameter를 고정된 값이 아닌 불확실성을 가진 확률 변수로 보고 데이터를 관찰하면서 업데이트 되는 값으로 보는 것이 핵심 ❗



### 사전확률(prior), 가능도(likelihood), 사후확률(posterior)

데이터 집합 $X$, 데이터가 따르는 확률 분포 $p(X)$가 있을 때, $p(X)$를 가장 잘 나타내는 $y=ax+b=\theta^\top\mathbf{x}$를 찾는 것이 목표이다. 

$$
\theta=
\begin{bmatrix}
a\\b
\end{bmatrix},
x=
\begin{bmatrix}
x\\1
\end{bmatrix}
$$

데이터 관찰 전, 파라미터 공간에 주어진 확률 분포 $p(\theta)$를 **prior(prior probability, 사전확률)**이라고 한다. (일반적인 정규분포나, 특정 확률 분포 등등)

**prior 분포**를 고정시킨다면, $p(X=x|\theta)$ 즉, 파라미터의 분포 $p(\theta)$가 정해졌을 때 $x$라는 데이터가 관찰될 확률 **likelihood(가능도, 우도)**를 계산할 수 있다. **likelihood**가 $\theta$에 의해 결정되는 함수이기 때문에 $\mathcal{L}(\theta|x)$라고 표현하기도 한다. 

**likelihood**가 높으면, 지정한 parameter 조건에서 데이터가 관찰될 확률이 높다는 것을 뜻하고 데이터의 분포를 모델이 잘 표현했다는 의미이다. 그렇기 때문에 데이터들의 **likelihood** 값을 최대화 하는 방향으로 모델을 학습시키는 방법을 **최대 우도 추정(maximum likelihood estimation, MLE)**라고 한다. 

반대로 $X$가 주어졌을 때, parameter $\theta$의 분포 $p(\theta|X)$는 **posterior(posterior probability, 사후 확률)**이라고 한다.  사후 확률을 구하는 것이 가장 좋지만, 데이터가 따르는 확률 분포 $p(X)$를 정확하게 알 수 없기 때문에 사후 확률을 계산해서 $\theta$값을 찾는 것이 아닌, 사전 확률과 우도에 관한 식으로 변형한 뒤, 그 식을 최대화하는 $\theta$를 찾는다. 사후확률을 최대화 하는 방향으로 모델을 학습시키는 방법을 **최대 사후 확률 추정(maximum a posteriori estimation, MAP)**라고 한다. 

확률의 곱셈 정리에 의해 확률 변수 $X$와 $θ$의 $p(X,θ)$는 다음과 같이 나타낼 수 있다.
$$
\begin{align}
p(X,θ)&=p(θ|X)p(X)=p(X|θ)p(θ)\\
\\
p(\theta|X)&=\frac{p(X|\theta) p(\theta)}{p(X)}\\
\\
\textrm{posterior} &= \frac{\textrm{likelihood}\times\textrm{prior}}{\textrm{evidence}}
\end{align}
$$

> 정확한 $p(X)$를 구할 수 없지만 $p(X)$는 고정된 값이기 때문에, 계산이 가능한 likelihood와 prior로 우변을 최대화 하는 parameter를 구하는 것이다. 
> 
<p align="center">
  <img src="/post_i/post3/1.PNG">
</p>

모델인 $y=x+1$에서 멀어지면, 데이터의 likelihood는 기하급수적으로 감소한다. 데이터들의 likelihood 값을 크게 하는 모델 파라미터를 찾는 방법을 **최대 가능도 추론(maximum likelihood estimation, MLE)**라고 한다. 



### 최대 가능도 추론(maximum likelihood estimation, MLE)

모델 파라미터 $\theta$가 주어졌을 때, 데이터 $(x_n, y_n)$의 likelihood는 다음과 같다. 
$$
p(y_n|\mathbf{\theta}, \mathbf{x}_n) = \mathcal{N}(y_n|\mathbf{\theta}^\top\mathbf{x}_n, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left({-\frac{(y_n-\mathbf{\theta}^\top\mathbf{x}_n)^2}{2\sigma^2}}\right)
$$
데이터 셋 전체의 likelihood $p(Y|\theta, X)$는 각 데이터의 likelihood를 모두 곱한 값과 같다. 
$$
p(Y|\mathbf{\theta}, X) = \prod_n p(y_n|\mathbf{\theta}, \mathbf{x}_n)
$$
$log$를 씌우면 곱셈 연산이 덧셈 연산으로 바뀌어 미분이 편리하고, 위의 그래프에서 본 것 처럼, likelihood는 0에 가까운 값으로 계산되는 경우가 많기 때문에 $\log$를 씌워서 계산한다. 
$$
\begin{align}
log_p(Y|\theta,X) &= log\prod_n p(y_n|\theta,~\mathbf{x}_n)\\
&=\sum_n log~p(y_n|\theta, \mathbf{x}_n)\\
&=\sum_n log\bigg(\frac{1}{\sqrt{2\pi\sigma^2}}exp\bigg(-\frac{(y_n-\theta^\top\mathbf{x}_n)^2}{2\sigma^2}\bigg)\bigg)\\
&=\sum_n log \frac{1}{\sqrt{2\pi\sigma^2}}+\sum_n log ~ exp \bigg(-\frac{(y_n-\theta^\top\mathbf{x}_n)^2}{2\sigma^2}\bigg)\\
&=\sum_n log \frac{1}{\sqrt{2\pi\sigma^2}}+\sum_n\bigg(-\frac{(y_n-\theta^\top\mathbf{x}_n)^2}{2\sigma^2}\bigg)\\
&=constant+\frac{1}{2\sigma^2}\sum_n(-(y_n-\theta^\top\mathbf{x})^2)
\end{align}
$$
likelihood를 최대화하는 parameter를 $\mathbf{\theta}_{ML}$(ML: maximum likelihood)이라고 하면, $\mathbf{\theta}_{ML}$는 다음과 같다. 
$$
\begin{align}
\mathbf{\theta}_{ML}&=arg~\max_\mathbf{\theta}~log~p(Y|\theta, X)\\
&=arg~\max_\mathbf{\theta}\bigg(\frac{1}{2\sigma^2}\sum_n(-(y_n-\theta^\top\mathbf{x}_n)^2)+constant\bigg)
\end{align}
$$
$log~likelihood$를 최대화하는 대신 손실 함수를 최소화하는 관점에서, **$negative log likelihood,~ (-log~p(Y|\theta, \mathbf{X}_n))$**를 최소화하는 식으로 나타내기도 한다. 
$$
\mathbf{\theta}_{ML} = \arg\min_\mathbf{\theta} \frac{1}{2\sigma^2} \sum_n (y_n-\mathbf{\theta}^\top\mathbf{x}_n)^2
$$
우리가 최소화해야 할 식을 $\mathbf{\theta}$에 대한 함수 $\mathcal{L}(\mathbf{\theta})$로 놓으면 $\mathcal{L}(\mathbf{\theta})$를 최소화하는 $\mathbf{\theta}$의 값은 $\mathcal{L}(\mathbf{\theta})$를 $\mathbf{\theta}$에 대해 미분한 식을 0으로 만드는 $\mathbf{\theta}$의 값과 같다. ($\mathcal{L}(\mathbf{\theta})$는 $\mathbf{\theta}$에 대한 이차식이므로 유일한 최솟값을 가진다.)
$$
\mathcal{L}(\mathbf{\theta}) = \frac{1}{2\sigma^2} \sum_n (y_n-\mathbf{\theta}^\top\mathbf{x}_n)^2
$$

$$
\begin{align}
\frac{d\mathcal{L}}{d\theta}&=\frac{d}{d\theta}\bigg(\frac{1}{2\sigma^2}\sum_n(y_n-\theta^\top\mathbf{x}_n)^2\bigg)\\
&=\frac{d}{d\theta}\bigg(\frac{1}{2\sigma^2}\sum_n)(y_n-\mathbf{x}_n^\top\theta)^2\bigg)\\
&=_{(1)} \frac{1}{2\sigma^2}\frac{d}{d\theta}(\mathbf{y}-X\theta)^\top(\mathbf{y}-X\theta)\\
&= \frac{1}{2\sigma^2}\frac{d}{d\theta}(\mathbf{y}^\top\mathbf{y}-\mathbf{y}^\top X\theta-\theta^\top X^\top\mathbf{y}+\theta^\top X^\top X\theta)\\
&=_{(2)} \frac{1}{2\sigma^2}\frac{d}{d\theta}(\mathbf{y}^\top\mathbf{y}-2\mathbf{y}^\top X\theta+\theta^\top X^\top X\theta)\\
&=_{(3)}\frac{1}{\sigma^2}\big(-\mathbf{y}^\top X+\theta^\top X^\top X\big)
\end{align}
$$

$$
\begin{align}
\frac{d\mathcal{L}}{d\theta}=0\Leftrightarrow\frac{1}{\sigma^2}\big(-\mathbf{y}^\top X+\theta^\top X^\top X\big)&=0^\top\theta_{ML}^\top X^\top X\\
&=\mathbf{y}^\top X
\end{align}
$$

$$
\begin{align}
\theta_{ML}^\top &=\mathbf{y}^\top X(X^\top X)^{-1}\\
\theta_{ML} &=(X^\top X)^{-1}X^\top\mathbf{y}
\end{align}
$$

따라서, 데이터셋 $X=[\mathbf{x}_1 \mathbf{x}_2 \dots \mathbf{x}_n]^\top \in \mathbb{R}^{n \times d}$(d차원 데이터 $\mathbf{x}*_n=[x_*{n1} \dots x_{nd}]^\top$), 라벨 $\mathbf{y}=[y_1 y_2 \dots y*_n]^\top$일 때, 최적 파라미터 $\mathbf{\theta}_*{ML}$은 다음과 같다. 
$$
\mathbf{\theta}_{ML} = (X^\top X)^{-1}X^\top\mathbf{y}
$$
